<h1>
  <img src="docs/imagens/logo.png" alt="logo61" width="50" style="vertical-align:middle;"> 
  Tech Challenge 2 (Fase 2): Pipeline Batch Bovespa: IngestÃ£o e Arquitetura de dados
</h1>

**Tech Challenge** Ã© um projeto que reÃºne a aplicaÃ§Ã£o dos conhecimentos adquiridos em todas as disciplinas de uma fase da EspecializaÃ§Ã£o em Machine Learning Engineering da FIAP PosTech.

Para o Tech Challenge 2, o desafio proposto foi o seguinte:

> ğŸ“¢ **Problema:** construa um pipeline de dados completo para **Extrair, Processar e Analisar dados do pregÃ£o da B3 (IBovespa)**, utilizando AWS S3, Glue, Lambda e Athena. Para acessar os dados, obrigatoriamente acessar o link: [Carteira TeÃ³rica o IBovespa](https://sistemaswebb3-listados.b3.com.br/indexPage/day/IBOV?language=pt-br)

Para este desafio as entregas devem ser realizadas utilizando tecnologias da **Amazon Cloud** e atender aos seguintes **Requisitos/objetivos**:

â€¢ **Requisito 1:** realizar o scrap de dados do site da B3 (IBovespa), extraindo dados do pregÃ£o (dados brutos).

â€¢ **Requisito 2:** os dados brutos devem ser ingeridos no S3 em formato parquet com partiÃ§Ã£o diÃ¡ria.

â€¢ **Requisito 3:** o Bucket S3 deve acionar uma Lambda, que por sua vez irÃ¡ chamar um job de ETL no Glue.

â€¢ **Requisito 4:** a Lambda pode ser em qualquer linguagem. Ela apenas deverÃ¡ iniciar o job Glue.

â€¢ **Requisito 5:** o job Glue deve ser feito no modo visual. Este job deve conter as seguintes transformaÃ§Ãµes obrigatÃ³rias:


 
<ol style="list-style-type: lower-alpha">
  <li>Realizar agrupamento numÃ©rico, sumarizaÃ§Ã£o, contagem ou soma;</li>
  <li>Renomear duas colunas existentes, alÃ©m das colunas de agrupamento;</li>
  <li>Realizar um cÃ¡lculo com campos de data; por exemplo, poder ser duraÃ§Ã£o, comparaÃ§Ã£o ou diferenÃ§a entre datas.</li>
</ol>

â€¢ **Requisito 6:** os dados refinados no job Glue devem ser salvos no formato parquet em uma pasta chamada REFINED, particionados por data e pelo nome ou abreviaÃ§Ã£o da aÃ§Ã£o do pregÃ£o.

â€¢ **Requisito 7:** o job Glue deve automaticamente catalogar o dado no Glue Catalog e criar uma tabela no banco de dados default do Glue Catalog.

â€¢ **Requisito 8:** os dados devem estar disponÃ­veis e legÃ­veis no Athena.

â€¢ **Requisito 9:** (OPCIONAL) construir um notebook no Athena para realizar uma visualizaÃ§Ã£o grÃ¡fica dos dados ingeridos.

â€¢ **Requisito 10:** (OPCIONAL) construir uma Pipeline Stream Bitcoin, conforme arquitetura de referÃªncia fornecida.

## ğŸ“Œ Objetivos

- Elaborar a **Arquitetura do projeto**, demonstrando todas as fases da pipeline;
- Implementar as tecnologias para o atendimento dos requisitos da Pipeline de IngestÃ£o de Dados da B3;
- Documentar o projeto de forma a permitir a sua reproduÃ§Ã£o;
- Disponibilizar a documentaÃ§Ã£o em um repositÃ³rio no **GitHub**.

## PossÃ­veis dores

- Falta de automaÃ§Ã£o na obtenÃ§Ã£o dos dados bem como seu tratamento;
- Falta de padronizaÃ§Ã£o para acesso aos dados bem como tipos de retornos e formatos mais adequados para consumo na produÃ§Ã£o de consultas e analytics;
- Suporte e documentaÃ§Ã£o insuficientes;
- RedundÃ¢ncia de dados em histÃ³rico confiÃ¡vel, com fonte de dados prÃ³pria;
- Baixa capacidade de anÃ¡lise em questÃµes relevantes para o usuÃ¡rio final.

## Proposta de soluÃ§Ã£o

Em face ao desafio proposto, algumas funcionalidades propostas (stages) para a Pipeline Batch Bovespa:

- IngestÃ£o de dados: coleta automÃ¡tica de dados (webscraping) extraÃ­dos do site B3 (IBovespa), por meio de uma Lambda que Ã© iniciada por um evento agendado;
- Armazenamento de dados: salvamento dos dados bruto (RAW) em parquet, com partiÃ§Ã£o diÃ¡ria, dentro Bucket S3;
- Processamento: limpeza, transformaÃ§Ã£o e padronizaÃ§Ã£o, usando script em Glue acionado assim que um novo arquivo Ã© carregado no Bucket S3;
- Carga final: gravaÃ§Ã£o de dado procesado (REFINED), com partiÃ§Ã£o diÃ¡ria, em Bucket S3;
- CatalogaÃ§Ã£o: atualizaÃ§Ã£o do catÃ¡logo do glue informando a partiÃ§Ã£o diÃ¡ria que foi criada;
- AgregaÃ§Ãµes e CÃ¡lculos: agregaÃ§Ãµes e cÃ¡lculos realizados nos dados refinados extraÃ­dos via athena e analisados no Google Colab;
- Consumo: leitura dos dados refinados e agregados para a produÃ§Ã£o de relatÃ³rios e dashboards, usando Athena e Google Colab.



**Importante**

Toda a implementaÃ§Ã£o foi feita via Terraform, com o princÃ­pio de **Infrastructure as a Code**, e estÃ¡ documentada neste repositÃ³rio. Consulte a [documentaÃ§Ã£o principal](docs/README.md) para mais detalhes.


### ğŸ“‚ Estrutura do projeto

```
terraform-infra-pipeline-aws/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ develop.yaml
â”‚       â”œâ”€â”€ prod.yaml
â”‚       â””â”€â”€ terraform.yaml
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ main.py             # Script principal do Job Glue
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ ...                 # MÃ³dulos Python auxiliares para o Glue
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ imagens/
â”‚   â”‚   â””â”€â”€ ...                 # Diagramas e imagens do projeto
â”‚   â””â”€â”€ license/
â”‚       â””â”€â”€ license.txt
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ envs/
â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”‚   â””â”€â”€ terraform.tfvars  # VariÃ¡veis especÃ­ficas do ambiente de DEV
â”‚   â”‚   â””â”€â”€ prod/
â”‚   â”‚       â””â”€â”€ terraform.tfvars  # VariÃ¡veis especÃ­ficas do ambiente de PROD
â”‚   â”œâ”€â”€ modules/                # MÃ³dulos Terraform reutilizÃ¡veis
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ main.tf                 # Arquivo principal com a definiÃ§Ã£o dos recursos
â”‚   â”œâ”€â”€ variables.tf            # DeclaraÃ§Ã£o das variÃ¡veis de entrada
â”‚   â”œâ”€â”€ versions.tf             # VersÃµes do Terraform e dos providers
â”‚   â””â”€â”€ backend.tf              # ConfiguraÃ§Ã£o do state remoto
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ lambda_function.py      # CÃ³digo da Lambda que inicia o Job Glue
â”‚   â””â”€â”€ lambda_functions_scrapper.py # CÃ³digo da Lambda que faz o scraping
â””â”€â”€ README.md                   # DocumentaÃ§Ã£o do projeto
```

### ğŸ”© Arquitetura da soluÃ§Ã£o

A arquitetura da soluÃ§Ã£o foi desenhada com base nos stages necessÃ¡rios ao atendimento de requisitos e consta na pasta de documentaÃ§Ã£o deste repositÃ³rio
![Arquitetura da SoluÃ§Ã£o](docs/imagens/Tech_Challenge_01_-_Arquitetura_de_Solucao.png)


Em face ao desafio proposto, segue detalhes da soluÃ§Ã£o:

1.  **ExtraÃ§Ã£o de Dados (Scraping)**
    *   Event Bridge com um evento agendado 1 vez ao dia.
    *   Lambda Ã© invocada pelo evento e realiza o scrap da pÃ¡gina da B3.
2.  **IngestÃ£o no Amazon S3**
    *   Salva os dados brutos em formato parquet dentro de um bucket S3 com partiÃ§Ã£o diÃ¡ria de acordo com a data do pregÃ£o.
3.  **Evento de notificaÃ§Ã£o do S3**
    *   Uma notificaÃ§Ã£o Ã© enviada pelo S3 para uma lambda a cada novo arquivo de dados brutos que Ã© carregado no bucket.
4.  **TransformaÃ§Ã£o com AWS Glue**
    *   A lambda invocada inicia o processamento do Glue Job.
    *   O glue job realiza as seguintes operaÃ§Ãµes:
        *   Leitura do arquivo parquet com dados brutos.
        *   Realiza conversÃ£o dos dados numÃ©ricos da nomenclatura BR para UI.
        *   Renomeia as colunas e carrega os dados na tabela de resultados refinados.
        *   Disponibiliza os dados via Athena.
5.  **RealizaÃ§Ã£o de anÃ¡lises de dados refinados**
    *   ExtraÃ§Ã£o dos dados refinados e cÃ³pia para o Google Colab para realizaÃ§Ã£o das seguintes operaÃ§Ãµes:
        *   AgregaÃ§Ã£o: total de negociaÃ§Ãµes por aÃ§Ã£o.
        *   CÃ¡lculo temporal: anÃ¡lise de partiÃ§Ã£o em cada aÃ§Ã£o.


## VÃ­deo de ApresentaÃ§Ã£o no Youtube
Para melhor compreensÃ£o da entrega, foi produzido um vÃ­deo de apresentaÃ§Ã£o que foi publicado no Youtube:

[Link para a VÃ­deo](inserir link)


## âœ’ï¸ Autores

| Nome                            |   RM    | Link do GitHub                                      |
|---------------------------------|---------|-----------------------------------------------------|
| Ana Paula de Almeida            | 363602  | [GitHub](https://github.com/Ana9873P)               |
| Augusto do Nascimento Omena     | 363185  | [GitHub](https://github.com/AugustoOmena)           |
| Bruno Gabriel de Oliveira       | 361248  | [GitHub](https://github.com/brunogabrieldeoliveira) |
| JosÃ© Walmir GonÃ§alves Duque     | 363196  | [GitHub](https://github.com/WALMIRDUQUE)            |
| Pedro Henrique da Costa Ulisses | 360864  | [GitHub](https://github.com/ordepzero)              |

## ğŸ“„ LicenÃ§a


Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT.  
Consulte o arquivo [license](docs/license/license.txt)  para mais detalhes.